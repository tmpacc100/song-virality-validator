import datetime
import calendar
import csv
import json
import os
import re
import urllib.parse
import requests
from bs4 import BeautifulSoup
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError

# YouTube APIè¨­å®šï¼ˆè¤‡æ•°ã®ã‚­ãƒ¼ã‚’ãƒªã‚¹ãƒˆã§ç®¡ç†ï¼‰
YOUTUBE_API_KEYS = [
    "AIzaSyCJGKejEe2kWJL2_OaXgqP2__jndZEy588",
    "AIzaSyAYjocbnNJabLlrdAoi5ynmTZ05TOgumwE",
    "AIzaSyAxpi2HcJx88xGFnK0Dl1fs55Ge_wWye2s",
    "AIzaSyAau11IT5KoG-GMEEjph5PnIgLzcEPc3bg",
    "AIzaSyB4mI2gLeVQ38FJmc-LB2iAhgM4lmvRwXg",
    "AIzaSyAyZ1CX-itALbov6ehkcTbzOcYOU41Xhpc",
    "AIzaSyC7qvI2c0TDCBtOJAUDeXl6i17VVN-SEBI",
    "AIzaSyBj5AIrkv1wTUfa6VQK2ur8Ldx4h8IoETo",
    "AIzaSyBURv-z_cInwFq5pYNCr4CpJkvqLyMKCkI",
    "AIzaSyAnf54Nc8N6LP605ce1i-XESRV6an2WXFw",
    "AIzaSyDWfhm7MB6lyoU5QOLXs3dw6JDeCuTo_Gw",
    "AIzaSyCmIltqc6DQdmP5tYAUpTWRYmBQpFVXUvw",
    "AIzaSyBR1XE02737tE2sPvjcCzpji0sS7N4pvhA",
    "AIzaSyAAR8KMXFCKNzKVN6ZOI7auUC1R0PiffNs",
    "AIzaSyBZFye-ujRnbHVtIluKMNQZ_6CIQymRg2g",
    "AIzaSyBRGbHlkw9AoXC6vkFHxqUAUuxhErBhoQM",
    "AIzaSyAVU6CKXYGA3xXW8CeIoZgMujQqYl0eAqM",
    "AIzaSyDsny--LjcpRYFpMFCa2rAGZNrAatxHAZE",
    "AIzaSyDcA4yi9a6rmozfXQ7P9luYyXK9m8hewrY",
]

# ç¾åœ¨ä½¿ç”¨ä¸­ã®APIã‚­ãƒ¼ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
current_api_key_index = 0
youtube = build('youtube', 'v3', developerKey=YOUTUBE_API_KEYS[current_api_key_index])


def switch_to_next_api_key():
    """æ¬¡ã®YouTube APIã‚­ãƒ¼ã«åˆ‡ã‚Šæ›¿ãˆã‚‹

    Returns:
        bool: åˆ‡ã‚Šæ›¿ãˆã«æˆåŠŸã—ãŸå ´åˆTrueã€å…¨ã¦ã®ã‚­ãƒ¼ã‚’ä½¿ã„åˆ‡ã£ãŸå ´åˆFalse
    """
    global current_api_key_index, youtube

    current_api_key_index += 1

    if current_api_key_index >= len(YOUTUBE_API_KEYS):
        return False  # å…¨ã¦ã®ã‚­ãƒ¼ã‚’ä½¿ã„åˆ‡ã£ãŸ

    # æ–°ã—ã„ã‚­ãƒ¼ã§YouTubeã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å†æ§‹ç¯‰
    youtube = build('youtube', 'v3', developerKey=YOUTUBE_API_KEYS[current_api_key_index])
    print(f"\nğŸ”‘ APIã‚­ãƒ¼ã‚’åˆ‡ã‚Šæ›¿ãˆã¾ã—ãŸï¼ˆã‚­ãƒ¼ {current_api_key_index + 1}/{len(YOUTUBE_API_KEYS)}ï¼‰")

    return True

# ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆRAW DATAãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¿å­˜ï¼‰
CACHE_FILE = 'RAW DATA/Youtube_API_raw.json'
RANKINGS_FILE = 'rankings.json'
TASKS_FILE = 'tasks.json'


def load_cache():
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’èª­ã¿è¾¼ã‚€"""
    if os.path.exists(CACHE_FILE):
        with open(CACHE_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    return []


def save_cache(data):
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä¿å­˜"""
    # RAW DATAãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    os.makedirs('RAW DATA', exist_ok=True)
    with open(CACHE_FILE, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)


def is_cache_valid(cached_date_str):
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒ1æ—¥ä»¥å†…ã‹ãƒã‚§ãƒƒã‚¯"""
    cached_date = datetime.datetime.fromisoformat(cached_date_str)
    now = datetime.datetime.now(datetime.timezone.utc)
    delta = now - cached_date
    return delta.total_seconds() < 86400  # 24æ™‚é–“


def extract_artist_from_title(video_title):
    """å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåã‚’æŠ½å‡º

    å„ªå…ˆé †ä½:
    1. ã€artistã€‘pattern â†’ artistï¼ˆãƒã‚¤ã‚ºé™¤å»ï¼‰
    2. artist - song pattern â†’ artist
    3. / artist : pattern â†’ artist
    4. / artist pattern â†’ artistï¼ˆãƒã‚¤ã‚ºé™¤å»ï¼‰

    Args:
        video_title: YouTubeå‹•ç”»ã®ã‚¿ã‚¤ãƒˆãƒ«

    Returns:
        æŠ½å‡ºã•ã‚ŒãŸã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåã€ã¾ãŸã¯ None
    """
    if not video_title:
        return None

    # ãƒ‘ã‚¿ãƒ¼ãƒ³1: ã€artistã€‘ï¼ˆè§’æ‹¬å¼§å†…ï¼‰
    match = re.search(r'ã€(.+?)ã€‘', video_title)
    if match:
        artist = match.group(1).strip()
        # ãƒã‚¤ã‚ºãƒ¯ãƒ¼ãƒ‰ã‚’é™¤å»ï¼ˆç•ªçµ„åãªã©ï¼‰
        noise_words = ['ç¬¬', 'å›', 'æ­Œåˆæˆ¦', 'NHK', 'ç´…ç™½', 'MV', 'MUSIC', 'Official', 'ã‚ªãƒªã‚¸ãƒŠãƒ«æ¥½æ›²', 'æ­Œå”±æ›²']
        if not any(noise in artist for noise in noise_words):
            return artist

    # ãƒ‘ã‚¿ãƒ¼ãƒ³2: artistï½¢songï½£ ã¾ãŸã¯ artistã€Œsongã€ï¼ˆå…¨è§’æ‹¬å¼§ã®å‰ï¼‰
    match = re.match(r'^([^\ï½¢ã€Œ]+)[ï½¢ã€Œ]', video_title)
    if match:
        return match.group(1).strip()

    # ãƒ‘ã‚¿ãƒ¼ãƒ³3: artist - songï¼ˆãƒã‚¤ãƒ•ãƒ³ã®å‰ï¼‰
    match = re.match(r'^(.+?)\s*[-âˆ’ãƒ¼]\s*', video_title)
    if match:
        return match.group(1).strip()

    # ãƒ‘ã‚¿ãƒ¼ãƒ³4: / artist :ï¼ˆã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã®å¾Œã€ã‚³ãƒ­ãƒ³ã®å‰ï¼‰
    match = re.search(r'/\s*(.+?)[:ï¼š]', video_title)
    if match:
        return match.group(1).strip()

    # ãƒ‘ã‚¿ãƒ¼ãƒ³5: / artistï¼ˆã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã®å¾Œï¼‰
    match = re.search(r'/\s*(.+?)$', video_title)
    if match:
        artist = match.group(1).strip()
        # MUSIC VIDEOã€MVã€æ‹¬å¼§å†…ãªã©ã®ãƒã‚¤ã‚ºã‚’é™¤å»
        artist = re.sub(r'\s*(MUSIC\s+VIDEO|MV|Official.*|[\(\ï¼ˆ].*?[\)\ï¼‰]).*$', '', artist, flags=re.IGNORECASE)
        return artist.strip() if artist else None

    # ãƒ‘ã‚¿ãƒ¼ãƒ³6: artist 'song' ã¾ãŸã¯ artist "song"ï¼ˆåŠè§’å¼•ç”¨ç¬¦ã®å‰ã€ã‚¹ãƒšãƒ¼ã‚¹å¿…é ˆï¼‰
    match = re.match(r'^(.+?)\s+[\'""'']', video_title)
    if match:
        artist = match.group(1).strip()
        # feat.ã‚’å«ã‚€å ´åˆã¯ãã“ã§åˆ‡ã‚‹
        artist = re.sub(r'\s+feat\..*$', '', artist, flags=re.IGNORECASE)
        return artist

    return None


# def fetch_pianogame_artists():
#     """PianoGameã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆæƒ…å ±ã‚’å–å¾—
#
#     Returns:
#         dict: {æ›²å: ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆå} ã®è¾æ›¸
#     """
#     from bs4 import BeautifulSoup
#
#     username = 'shii'
#     password = '0619'
#     notifications_url = 'https://pianogame-server.herokuapp.com/notifications'
#
#     artists_dict = {}
#
#     try:
#         # Basicèªè¨¼ã§ã‚¢ã‚¯ã‚»ã‚¹
#         print("  PianoGameã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆæƒ…å ±ã‚’å–å¾—ä¸­...")
#         response = requests.get(notifications_url, auth=(username, password))
#
#         if response.status_code != 200:
#             print(f"  âš  ã‚µãƒ¼ãƒãƒ¼ã‚¢ã‚¯ã‚»ã‚¹å¤±æ•—: {response.status_code}")
#             return artists_dict
#
#         soup = BeautifulSoup(response.text, 'html.parser')
#
#         # ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰æƒ…å ±ã‚’æŠ½å‡º
#         table = soup.find('table')
#         if table:
#             rows = table.find_all('tr')[1:]  # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—
#
#             for row in rows:
#                 cols = row.find_all('td')
#                 if len(cols) >= 5:
#                     body = cols[2].get_text(strip=True)  # "Body"åˆ—
#                     song_name = cols[4].get_text(strip=True)  # "Song"åˆ—
#
#                     # Bodyåˆ—ã‹ã‚‰ã€Œã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåã€Œæ›²åã€ã‚’è¿½åŠ ã—ã¾ã—ãŸã€ã‚’æŠ½å‡º
#                     # å½¢å¼: ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåã€Œæ›²åã€ã‚’è¿½åŠ ã—ã¾ã—ãŸï¼ãœã²ã‚ãã‚“ã§ã¿ã¦ã­â™ª
#                     # ã¾ãŸã¯: ãŸãã•ã‚“ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®ä¸­ã‹ã‚‰ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåã€Œæ›²åã€ã‚’è¿½åŠ ã—ã¾ã—ãŸ
#
#                     # ã€Œã€ã®ç›´å‰ã®ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåã‚’æŠ½å‡ºï¼ˆæœ€å¾Œã®ã€Œã®å‰ã®éƒ¨åˆ†ï¼‰
#                     # ã¾ãšã€Œæ›²åã€ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¢ã™
#                     match = re.search(r'([^ã€Œã€]+)ã€Œ[^ã€]+ã€ã‚’è¿½åŠ ã—ã¾ã—ãŸ', body)
#                     if match:
#                         # ãƒãƒƒãƒã—ãŸéƒ¨åˆ†ã‹ã‚‰ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåã‚’æŠ½å‡º
#                         # "ãŸãã•ã‚“ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®ä¸­ã‹ã‚‰Saucy Dog" â†’ "Saucy Dog"
#                         artist_part = match.group(1)
#                         # "ã‹ã‚‰"ã¾ãŸã¯"ã§"ã®å¾Œã‚ã‚’å–å¾—ã€ãªã‘ã‚Œã°å…¨ä½“
#                         artist = re.split(r'(?:ã‹ã‚‰|ã§)', artist_part)[-1].strip()
#                         if artist:
#                             artists_dict[song_name] = artist
#
#         print(f"  âœ“ PianoGameã‹ã‚‰ {len(artists_dict)} æ›²ã®ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆæƒ…å ±ã‚’å–å¾—ã—ã¾ã—ãŸ")
#
#     except Exception as e:
#         print(f"  âš  PianoGameã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰ã®å–å¾—ã«å¤±æ•—: {e}")
#
#     return artists_dict


def fetch_taikogame_artists():
    """TaikoGameã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰æ›²æƒ…å ±ã‚’å–å¾—

    Returns:
        tuple: (artists_dict, songs_list)
            - artists_dict: {æ›²å: ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆå} ã®è¾æ›¸ï¼ˆå¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ï¼‰
            - songs_list: å…¨14åˆ—ã®ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€è¾æ›¸ã®ãƒªã‚¹ãƒˆ
    """
    username = 'shii'
    password = '0619'
    songs_url = 'https://taikogame-server.herokuapp.com/songs'

    artists_dict = {}
    songs_list = []

    try:
        print("  TaikoGameã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰æ›²æƒ…å ±ã‚’å–å¾—ä¸­...")
        response = requests.get(songs_url, auth=(username, password))

        if response.status_code != 200:
            print(f"  âš  ã‚µãƒ¼ãƒãƒ¼ã‚¢ã‚¯ã‚»ã‚¹å¤±æ•—: {response.status_code}")
            return artists_dict, songs_list

        # HTMLã‚’ãƒ‘ãƒ¼ã‚¹
        soup = BeautifulSoup(response.text, 'html.parser')

        # ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰æƒ…å ±ã‚’æŠ½å‡º
        table = soup.find('table')
        if not table:
            print("  âš  ãƒ†ãƒ¼ãƒ–ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return artists_dict, songs_list

        rows = table.find_all('tr')[1:]  # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—

        for row in rows:
            cols = row.find_all('td')
            if len(cols) >= 12:  # ãƒªãƒªãƒ¼ã‚¹çŠ¶æ…‹åˆ—ã¾ã§å­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèª
                # cols[0]=ID, cols[1]=ãƒªãƒªãƒ¼ã‚¹æ—¥, cols[2]=Title, cols[3]=ãµã‚ŠãŒãª
                # cols[4]=ç·¨é›†, cols[5]=ã‚¿ã‚°, cols[6]=ãƒ‡ãƒ¼ã‚¿, cols[7]=Jasrac code
                # cols[8]=é›£æ˜“åº¦, cols[9]=youtube, cols[10]=ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰, cols[11]=ãƒªãƒªãƒ¼ã‚¹çŠ¶æ…‹

                # ãƒªãƒªãƒ¼ã‚¹çŠ¶æ…‹ã‚’å–å¾—
                release_status = cols[11].get_text(strip=True)

                # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãªã— - å…¨ã¦ã®æ›²ã‚’å–å¾—
                # ï¼ˆä»¥å‰ã¯ã€Œãƒªãƒªãƒ¼ã‚¹ã€ã¾ãŸã¯ã€Œé–‹ç™ºä¸­ã€ã®ã¿ã ã£ãŸï¼‰

                # å…¨12åˆ—ã‚’å–å¾—
                id_value = cols[0].get_text(strip=True)
                release_date = cols[1].get_text(strip=True)
                title_text = cols[2].get_text(separator='\n')
                furigana = cols[3].get_text(strip=True)
                edit = cols[4].get_text(strip=True)
                tags = cols[5].get_text(strip=True)
                data = cols[6].get_text(strip=True)
                jasrac_code = cols[7].get_text(strip=True)
                difficulty = cols[8].get_text(strip=True)
                youtube = cols[9].get_text(strip=True)
                download = cols[10].get_text(strip=True)

                # æ”¹è¡Œã§åˆ†å‰²ã—ã¦ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåã¨æ›²åã‚’æŠ½å‡º
                # æ§‹é€ : è¡Œ1=æ›²å, è¡Œ2=ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆå, è¡Œ3=ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆèª­ã¿, è¡Œ4=ä¸»é¡Œæ­Œæƒ…å ±
                lines = [line.strip() for line in title_text.split('\n') if line.strip()]

                song_name = ''
                artist_name = ''

                if len(lines) >= 2:
                    # è¡Œ1: æ›²å
                    song_name = lines[0]
                    # è¡Œ2: ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆå
                    artist_name = lines[1]

                if song_name and artist_name:
                    artists_dict[song_name] = artist_name

                # å…¨ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
                songs_list.append({
                    'id': id_value,
                    'release_date': release_date,
                    'title': title_text.replace('\n', ' '),
                    'furigana': furigana,
                    'edit': edit,
                    'tags': tags,
                    'data': data,
                    'jasrac_code': jasrac_code,
                    'difficulty': difficulty,
                    'youtube': youtube,
                    'download': download,
                    'release_status': release_status,
                    'song_name': song_name if song_name else '',
                    'artist_name': artist_name if artist_name else ''
                })

        print(f"  âœ“ TaikoGameã‹ã‚‰ {len(songs_list)} æ›²ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã—ãŸï¼ˆå…¨ã¦ã®æ›²ã‚’å«ã‚€ï¼‰")
        print(f"    ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåãŒæŠ½å‡ºã§ããŸæ›²: {len(artists_dict)}æ›²")

    except Exception as e:
        print(f"  âš  TaikoGameã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰ã®å–å¾—ã«å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()

    return artists_dict, songs_list


def fetch_itunes_artist(song_name):
    """iTunes APIã‹ã‚‰æ›²ã®ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåã‚’å–å¾—

    Args:
        song_name: æ›²å

    Returns:
        str: ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåã€è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯None
    """
    try:
        # iTunes Search API
        base_url = 'https://itunes.apple.com/search'
        params = {
            'term': song_name,
            'country': 'JP',  # æ—¥æœ¬ã®ã‚¹ãƒˆã‚¢
            'media': 'music',
            'entity': 'song',
            'limit': 5  # ä¸Šä½5ä»¶ã‚’å–å¾—
        }

        response = requests.get(base_url, params=params, timeout=10)

        if response.status_code != 200:
            return None

        data = response.json()
        results = data.get('results', [])

        if not results:
            return None

        # æœ€åˆã®çµæœã‹ã‚‰ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåã‚’å–å¾—
        # trackNameãŒæ›²åã¨ä¸€è‡´ã™ã‚‹ã‚‚ã®ã‚’å„ªå…ˆ
        for result in results:
            track_name = result.get('trackName', '')
            artist_name = result.get('artistName', '')

            # æ›²åãŒéƒ¨åˆ†ä¸€è‡´ã™ã‚‹å ´åˆã¯ãã®ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆã‚’è¿”ã™
            if song_name.lower() in track_name.lower() or track_name.lower() in song_name.lower():
                return artist_name

        # å®Œå…¨ä¸€è‡´ãŒãªã„å ´åˆã¯æœ€åˆã®çµæœã‚’è¿”ã™
        return results[0].get('artistName')

    except Exception:
        # iTunes APIã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–ã—ã¦Noneã‚’è¿”ã™ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãŒå‹•ä½œã™ã‚‹ï¼‰
        return None


def update_artist_names_in_data(songs_data):
    """ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåã‚’è¤‡æ•°ã®ã‚½ãƒ¼ã‚¹ã‹ã‚‰å–å¾—ã—ã¦æ›´æ–°

    å„ªå…ˆé †ä½:
    1. TaikoGameã‹ã‚‰å–å¾—ã—ãŸã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåï¼ˆæœ€å„ªå…ˆï¼‰
    2. å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰æŠ½å‡ºã—ãŸã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰

    Args:
        songs_data: æ›²ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆï¼ˆå„è¦ç´ ã¯è¾æ›¸ï¼‰

    Returns:
        æ›´æ–°ã•ã‚ŒãŸæ›²ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ
    """
    # TaikoGameã‹ã‚‰ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆæƒ…å ±ã‚’å–å¾—
    print("\n" + "="*60)
    print("TaikoGameã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆæƒ…å ±ã‚’å–å¾—")
    print("="*60)
    taikogame_artists, taikogame_full_data = fetch_taikogame_artists()

    updated_count = 0
    taikogame_count = 0
    # itunes_count = 0
    title_extraction_count = 0

    for song in songs_data:
        song_name = song.get('song_name', '')
        video_title = song.get('video_title', '')
        original_artist = song.get('artist_name', '')
        new_artist = None
        source = ''

        # å„ªå…ˆé †ä½1: TaikoGameã‹ã‚‰å–å¾—ï¼ˆæœ€å„ªå…ˆï¼‰
        if song_name in taikogame_artists:
            new_artist = taikogame_artists[song_name]
            source = 'TaikoGame'
            taikogame_count += 1

        # # å„ªå…ˆé †ä½2: iTunes APIã‹ã‚‰å–å¾—ï¼ˆã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆï¼‰
        # if not new_artist and song_name:
        #     itunes_artist = fetch_itunes_artist(song_name)
        #     if itunes_artist:
        #         new_artist = itunes_artist
        #         source = 'iTunes API'
        #         itunes_count += 1

        # å„ªå…ˆé †ä½2: å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰æŠ½å‡ºï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
        if not new_artist:
            new_artist = extract_artist_from_title(video_title, song_name)
            if new_artist:
                source = 'å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«'
                title_extraction_count += 1

        # ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåã‚’æ›´æ–°
        if new_artist and original_artist != new_artist:
            song['artist_name'] = new_artist
            updated_count += 1
            print(f"  æ›´æ–°: {original_artist} â†’ {new_artist} (ã‚½ãƒ¼ã‚¹: {source}, æ›²: {song_name})")

    print(f"\n" + "="*60)
    print(f"ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåæ›´æ–°çµæœ:")
    print(f"  - TaikoGameã‹ã‚‰å–å¾—: {taikogame_count}æ›²")
    # print(f"  - iTunes APIã‹ã‚‰å–å¾—: {itunes_count}æ›²")
    print(f"  - å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰æŠ½å‡º: {title_extraction_count}æ›²")
    print(f"  - æ›´æ–°ã•ã‚ŒãŸæ›²æ•°: {updated_count}æ›²")
    print("="*60)

    return songs_data


def search_youtube_video(song_name):
    """æ›²åã§YouTubeå‹•ç”»ã‚’æ¤œç´¢ã—ã¦æœ€ã‚‚é–¢é€£æ€§ã®é«˜ã„å‹•ç”»IDã¨ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—"""
    import time

    max_retries = 3
    for attempt in range(max_retries):
        try:
            print(f"  - æ¤œç´¢ã‚¯ã‚¨ãƒª: {song_name}")
            search_response = youtube.search().list(
                q=song_name,
                part='id,snippet',
                maxResults=5,
                type='video'
            ).execute()

            print(f"  - æ¤œç´¢çµæœæ•°: {len(search_response.get('items', []))}")

            if search_response['items']:
                video = search_response['items'][0]
                video_id = video['id']['videoId']
                video_title = video['snippet']['title']
                print(f"  - é¸æŠã•ã‚ŒãŸå‹•ç”»: {video_title} (ID: {video_id})")
                return video_id, video_title
            else:
                print(f"  - æ¤œç´¢çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                return None, None
        except HttpError as e:
            # ã‚¯ã‚ªãƒ¼ã‚¿ã‚¨ãƒ©ãƒ¼ã‚’ãƒã‚§ãƒƒã‚¯
            if e.resp.status == 403 and 'quotaExceeded' in str(e):
                print(f"  - âš  APIã‚¯ã‚ªãƒ¼ã‚¿åˆ¶é™ã«é”ã—ã¾ã—ãŸ")
                # æ¬¡ã®APIã‚­ãƒ¼ã«åˆ‡ã‚Šæ›¿ãˆ
                if switch_to_next_api_key():
                    print(f"  - ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™...")
                    continue  # åŒã˜æ›²ã§å†è©¦è¡Œ
                else:
                    print(f"  - âœ— å…¨ã¦ã®APIã‚­ãƒ¼ã‚’ä½¿ã„åˆ‡ã‚Šã¾ã—ãŸ")
                    raise  # ã‚¯ã‚ªãƒ¼ã‚¿ã‚¨ãƒ©ãƒ¼ã‚’ä¸Šä½ã«ä¼æ’­

            print(f"  - YouTubeæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            if attempt < max_retries - 1:
                print(f"  - ãƒªãƒˆãƒ©ã‚¤ {attempt + 1}/{max_retries - 1}...")
                time.sleep(2)
            else:
                return None, None
        except Exception as e:
            print(f"  - ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
            if attempt < max_retries - 1:
                print(f"  - ãƒªãƒˆãƒ©ã‚¤ {attempt + 1}/{max_retries - 1}...")
                time.sleep(2)
            else:
                print(f"  - æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°ã«é”ã—ã¾ã—ãŸã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                return None, None

    return None, None


def get_video_stats(video_id):
    """YouTubeå‹•ç”»ã®çµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
    import time

    max_retries = 3
    for attempt in range(max_retries):
        try:
            video_response = youtube.videos().list(
                id=video_id,
                part='statistics,snippet'
            ).execute()

            if not video_response['items']:
                return None

            video = video_response['items'][0]
            stats = video['statistics']
            snippet = video['snippet']

            # å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«ã¨ãƒãƒ£ãƒ³ãƒãƒ«åã‚’å–å¾—
            video_title = snippet.get('title', '')
            channel_title = snippet.get('channelTitle', '')

            published_at = snippet['publishedAt']
            published_date = datetime.datetime.fromisoformat(published_at.replace('Z', '+00:00'))

            now = datetime.datetime.now(datetime.timezone.utc)
            days_since_published = (now - published_date).days
            if days_since_published == 0:
                days_since_published = 1

            view_count = int(stats.get('viewCount', 0))
            like_count = int(stats.get('likeCount', 0))
            comment_count = int(stats.get('commentCount', 0))

            support_rate = (like_count / view_count * 100) if view_count > 0 else 0
            growth_rate = view_count / days_since_published

            return {
                'video_id': video_id,
                'video_title': video_title,
                'channel_title': channel_title,
                'view_count': view_count,
                'like_count': like_count,
                'comment_count': comment_count,
                'support_rate': support_rate,
                'growth_rate': growth_rate,
                'days_since_published': days_since_published,
                'published_date': published_at,
                'fetched_at': datetime.datetime.now(datetime.timezone.utc).isoformat()
            }
        except HttpError as e:
            # ã‚¯ã‚ªãƒ¼ã‚¿ã‚¨ãƒ©ãƒ¼ã‚’ãƒã‚§ãƒƒã‚¯
            if e.resp.status == 403 and 'quotaExceeded' in str(e):
                print(f"  - âš  APIã‚¯ã‚ªãƒ¼ã‚¿åˆ¶é™ã«é”ã—ã¾ã—ãŸ")
                # æ¬¡ã®APIã‚­ãƒ¼ã«åˆ‡ã‚Šæ›¿ãˆ
                if switch_to_next_api_key():
                    print(f"  - ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™...")
                    continue  # åŒã˜å‹•ç”»ã§å†è©¦è¡Œ
                else:
                    print(f"  - âœ— å…¨ã¦ã®APIã‚­ãƒ¼ã‚’ä½¿ã„åˆ‡ã‚Šã¾ã—ãŸ")
                    raise  # ã‚¯ã‚ªãƒ¼ã‚¿ã‚¨ãƒ©ãƒ¼ã‚’ä¸Šä½ã«ä¼æ’­

            print(f"  - å‹•ç”»çµ±è¨ˆå–å¾—ã‚¨ãƒ©ãƒ¼ ({video_id}): {e}")
            if attempt < max_retries - 1:
                print(f"  - ãƒªãƒˆãƒ©ã‚¤ {attempt + 1}/{max_retries - 1}...")
                time.sleep(2)
            else:
                return None
        except Exception as e:
            print(f"  - ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ ({video_id}): {type(e).__name__}: {e}")
            if attempt < max_retries - 1:
                print(f"  - ãƒªãƒˆãƒ©ã‚¤ {attempt + 1}/{max_retries - 1}...")
                time.sleep(2)
            else:
                print(f"  - æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°ã«é”ã—ã¾ã—ãŸã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                return None

    return None


def process_songs_from_csv(csv_file, use_cache=True, force_refresh=False):
    """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ›²åã‚’èª­ã¿è¾¼ã¿ã€YouTubeãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—

    Args:
        csv_file: CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        use_cache: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä½¿ç”¨ã™ã‚‹ã‹
        force_refresh: Trueã®å ´åˆã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ç„¡è¦–ã—ã¦å†å–å¾—
    """
    songs_data = []
    cache = {item['song_name']: item for item in load_cache()} if (use_cache and not force_refresh) else {}

    # å‡¦ç†ä¸­ã«ä¿å­˜ã™ã‚‹é–“éš”ï¼ˆæ›²æ•°ï¼‰
    SAVE_INTERVAL = 10
    processed_count = 0

    try:
        with open(csv_file, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)

            for row in reader:
                # TaikoGameã®CSVå½¢å¼ã«å¯¾å¿œ (song_nameåˆ—ã‚’ä½¿ç”¨)
                song_name = row.get('song_name', '').strip()
                release_date = row.get('release_date', '').strip()  # ML/RLã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ç”¨
                if not song_name:
                    continue

                print(f"å‡¦ç†ä¸­: {song_name}")

                # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯ï¼ˆforce_refreshãŒTrueã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰
                if use_cache and not force_refresh and song_name in cache:
                    cached_item = cache[song_name]
                    if 'fetched_at' in cached_item and is_cache_valid(cached_item['fetched_at']):
                        print(f"  - ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä½¿ç”¨")
                        songs_data.append(cached_item)
                        continue

                try:
                    # YouTubeå‹•ç”»ã‚’æ¤œç´¢
                    video_id, search_title = search_youtube_video(song_name)
                    if not video_id:
                        print(f"  - å‹•ç”»ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                        continue

                    # å‹•ç”»çµ±è¨ˆã‚’å–å¾—
                    stats = get_video_stats(video_id)
                    if not stats:
                        print(f"  - çµ±è¨ˆæƒ…å ±ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
                        continue

                except HttpError as e:
                    # YouTube APIã®ã‚¯ã‚ªãƒ¼ã‚¿ã‚¨ãƒ©ãƒ¼ã‚’ãƒã‚§ãƒƒã‚¯
                    if e.resp.status == 403 and 'quotaExceeded' in str(e):
                        print(f"\nâš  å…¨ã¦ã®YouTube APIã‚­ãƒ¼ï¼ˆ{len(YOUTUBE_API_KEYS)}å€‹ï¼‰ã®ã‚¯ã‚ªãƒ¼ã‚¿åˆ¶é™ã«é”ã—ã¾ã—ãŸ")
                        print(f"âœ“ ã“ã“ã¾ã§ã«å–å¾—ã—ãŸ {len(songs_data)} æ›²ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã™...")
                        save_cache(songs_data)
                        print(f"âœ“ ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {CACHE_FILE}")
                        print(f"\nğŸ’¡ ãƒ’ãƒ³ãƒˆ: ç¿Œæ—¥ã«ãªã‚‹ã¨ã‚¯ã‚ªãƒ¼ã‚¿ãŒãƒªã‚»ãƒƒãƒˆã•ã‚Œã¾ã™")
                        return songs_data
                    else:
                        print(f"  - YouTube APIã‚¨ãƒ©ãƒ¼: {e}")
                        continue
                except Exception as e:
                    print(f"  - ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                    continue

                # ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåå–å¾—ã®å„ªå…ˆé †ä½:
                # 1. iTunes Search API (exactãƒãƒƒãƒã®ã¿)
                # 2. å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰æŠ½å‡º
                # 3. iTunes Search API (candidateã‚‚ä½¿ç”¨)
                # 4. ãƒãƒ£ãƒ³ãƒãƒ«åã‹ã‚‰æŠ½å‡º

                video_title = stats.get('video_title', search_title or '')
                channel_title = stats.get('channel_title', '')

                # 1. iTunes Search APIã§æ¤œç´¢ï¼ˆå‹•ç”»æƒ…å ±ã‚’æ¸¡ã—ã¦ç²¾åº¦å‘ä¸Šï¼‰
                itunes_artist, itunes_confidence = get_artist_from_itunes(song_name, video_title, channel_title)

                # exactãƒãƒƒãƒã®å ´åˆã¯ãã®ã¾ã¾ä½¿ç”¨
                if itunes_confidence == "exact":
                    artist_name = itunes_artist
                else:
                    # 2. ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰æŠ½å‡ºã‚’è©¦ã¿ã‚‹
                    print(f"  ğŸ“º ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰æŠ½å‡ºã‚’è©¦ã¿ã¾ã™")
                    artist_name = extract_artist_from_title(video_title, song_name)

                    # 3. ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰æŠ½å‡ºã§ããšã€iTunesã«å€™è£œãŒã‚ã‚‹å ´åˆã¯å€™è£œã‚’ä½¿ç”¨
                    if not artist_name and itunes_confidence == "candidate":
                        artist_name = itunes_artist

                # ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåã«æ—¥æœ¬èªã¨ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆãŒæ··åœ¨ã—ã¦ã„ã‚‹å ´åˆã€æ—¥æœ¬èªã®ã¿æŠ½å‡º
                if artist_name and re.search(r'[ã-ã‚“ã‚¡-ãƒ¶ãƒ¼ä¸€-é¾¯]', artist_name):
                    # æœ«å°¾ã®ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆã‚’å‰Šé™¤
                    japanese_artist = re.sub(r'\s*[A-Za-z\s]+$', '', artist_name).strip()
                    # å…ˆé ­ã®ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆã‚‚å‰Šé™¤
                    japanese_artist = re.sub(r'^[A-Za-z\s]+\s*', '', japanese_artist).strip()
                    if japanese_artist:
                        artist_name = japanese_artist

                # 3. ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰æŠ½å‡ºã§ããªã„å ´åˆã¯ã€ãƒãƒ£ãƒ³ãƒãƒ«åã‚’ä½¿ç”¨
                # ãŸã ã—ã€ãƒãƒ£ãƒ³ãƒãƒ«åãŒæ›²åã¨åŒã˜å ´åˆã¯ä½¿ç”¨ã—ãªã„
                if not artist_name and channel_title:
                    print(f"  ğŸ“¢ ãƒãƒ£ãƒ³ãƒãƒ«åã‹ã‚‰æŠ½å‡ºã‚’è©¦ã¿ã¾ã™")
                    # ãƒãƒ£ãƒ³ãƒãƒ«åãŒæ›²åã¨é•ã†å ´åˆã®ã¿ä½¿ç”¨
                    if channel_title.lower() != song_name.lower():
                        # ã€Œãƒãƒ£ãƒ³ãƒãƒ«ã€ã‚„ã€Œchannelã€ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã€ãã®å‰ã®éƒ¨åˆ†ã‚’æŠ½å‡º
                        cleaned_channel = channel_title
                        if 'ãƒãƒ£ãƒ³ãƒãƒ«' in channel_title:
                            cleaned_channel = channel_title.split('ãƒãƒ£ãƒ³ãƒãƒ«')[0].strip()
                        elif 'channel' in channel_title.lower():
                            # å¤§æ–‡å­—å°æ–‡å­—ã‚’åŒºåˆ¥ã›ãšã«åˆ†å‰²
                            match = re.search(r'(.+?)\s*channel', channel_title, re.IGNORECASE)
                            if match:
                                cleaned_channel = match.group(1).strip()

                        # æ—¥æœ¬èªã¨ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆãŒæ··åœ¨ã—ã¦ã„ã‚‹å ´åˆã€æ—¥æœ¬èªéƒ¨åˆ†ã®ã¿ã‚’æŠ½å‡º
                        # ä¾‹: "ç±³æ´¥ç„å¸«  Kenshi Yonezu" -> "ç±³æ´¥ç„å¸«"
                        # ä¾‹: "Kenshi Yonezu  ç±³æ´¥ç„å¸«" -> "ç±³æ´¥ç„å¸«"
                        if re.search(r'[ã-ã‚“ã‚¡-ãƒ¶ãƒ¼ä¸€-é¾¯]', cleaned_channel):  # æ—¥æœ¬èªãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹
                            # æ—¥æœ¬èªã¨ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆãŒæ··åœ¨ã—ã¦ã„ã‚‹å ´åˆ
                            # æœ«å°¾ã®ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆã‚’å‰Šé™¤
                            japanese_part = re.sub(r'\s*[A-Za-z\s]+$', '', cleaned_channel).strip()
                            # å…ˆé ­ã®ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆã‚‚å‰Šé™¤
                            japanese_part = re.sub(r'^[A-Za-z\s]+\s*', '', japanese_part).strip()
                            if japanese_part:
                                cleaned_channel = japanese_part

                        # ã‚¯ãƒªãƒ¼ãƒ³å¾Œã®ãƒãƒ£ãƒ³ãƒãƒ«åãŒç©ºã§ãªã„å ´åˆã®ã¿ä½¿ç”¨
                        if cleaned_channel:
                            artist_name = cleaned_channel

                song_data = {
                    'song_name': song_name,
                    'artist_name': artist_name,
                    'release_date': release_date,  # ML/RLã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ç”¨
                    'video_id': video_id,
                    **stats
                }
                songs_data.append(song_data)
                processed_count += 1

                print(f"  - å®Œäº†: ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆ={artist_name or '(ä¸æ˜)'}, ãƒãƒ£ãƒ³ãƒãƒ«={channel_title}, å†ç”Ÿæ•°={stats['view_count']:,}, æ”¯æŒç‡={stats['support_rate']:.2f}%")

                # å®šæœŸçš„ã«ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ï¼ˆSAVE_INTERVALæ›²ã”ã¨ï¼‰
                if processed_count % SAVE_INTERVAL == 0:
                    print(f"\nğŸ’¾ {processed_count}æ›²å‡¦ç†å®Œäº†ã€‚ä¸­é–“ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ä¸­...")
                    save_cache(songs_data)
                    print(f"âœ“ ä¿å­˜å®Œäº†: {CACHE_FILE}\n")

    except KeyboardInterrupt:
        print(f"\n\nâš  å‡¦ç†ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
        print(f"âœ“ ã“ã“ã¾ã§ã«å–å¾—ã—ãŸ {len(songs_data)} æ›²ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã™...")
        save_cache(songs_data)
        print(f"âœ“ ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {CACHE_FILE}")
        return songs_data
    except Exception as e:
        print(f"\n\nâš  äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        print(f"âœ“ ã“ã“ã¾ã§ã«å–å¾—ã—ãŸ {len(songs_data)} æ›²ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã™...")
        save_cache(songs_data)
        print(f"âœ“ ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {CACHE_FILE}")
        return songs_data

    return songs_data


def create_rankings(songs_data):
    """å„ãƒ¡ãƒˆãƒªãƒƒã‚¯ã”ã¨ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã¨ç·åˆãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’ä½œæˆ"""
    if not songs_data:
        return {}

    rankings = {
        'popularity': sorted(songs_data, key=lambda x: x['view_count'], reverse=True),
        'support_rate': sorted(songs_data, key=lambda x: x['support_rate'], reverse=True),
        'engagement': sorted(songs_data, key=lambda x: x['comment_count'], reverse=True),
        'growth_rate': sorted(songs_data, key=lambda x: x['growth_rate'], reverse=True)
    }

    song_scores = {}
    for song in songs_data:
        song_name = song['song_name']
        total_rank = 0
        for metric_name, ranked_songs in rankings.items():
            rank = next(i for i, s in enumerate(ranked_songs) if s['song_name'] == song_name)
            total_rank += rank
        song_scores[song_name] = total_rank

    overall_ranking = sorted(songs_data, key=lambda x: song_scores[x['song_name']])
    rankings['overall'] = overall_ranking

    return rankings


def get_artist_from_itunes(song_name, video_title="", channel_title=""):
    """iTunes Search APIã‹ã‚‰ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåã‚’å–å¾—

    Args:
        song_name: æ›²å
        video_title: å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ã€ãƒãƒƒãƒãƒ³ã‚°ç²¾åº¦å‘ä¸Šã«ä½¿ç”¨ï¼‰
        channel_title: ãƒãƒ£ãƒ³ãƒãƒ«åï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ã€ãƒãƒƒãƒãƒ³ã‚°ç²¾åº¦å‘ä¸Šã«ä½¿ç”¨ï¼‰

    Returns:
        tuple: (ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆå, ç¢ºåº¦) - ç¢ºåº¦ã¯ "exact" ã¾ãŸã¯ "candidate" ã¾ãŸã¯ ""
    """
    try:
        # æ›²åã‚’URLã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        encoded_song = urllib.parse.quote(song_name)
        url = f"https://itunes.apple.com/search?term={encoded_song}&country=jp&media=music&limit=10"

        print(f"  ğŸµ iTunes APIã§æ¤œç´¢ä¸­: {song_name}")
        response = requests.get(url, timeout=10)

        if response.status_code == 200:
            data = response.json()
            results = data.get('results', [])

            if results:
                # å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«ã‚„ãƒãƒ£ãƒ³ãƒãƒ«åã«å«ã¾ã‚Œã‚‹ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆã‚’å„ªå…ˆ
                matched_artists = []
                for result in results:
                    artist = result.get('artistName', '')
                    track = result.get('trackName', '')

                    # æ›²åãŒä¸€è‡´ã—ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                    if not (song_name.lower() in track.lower() or track.lower() in song_name.lower()):
                        continue

                    # ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåã¨æ›²åãŒåŒã˜å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ï¼ˆèª¤æ¤œå‡ºï¼‰
                    if not artist or artist.lower() == song_name.lower():
                        continue

                    # å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«ã‚„ãƒãƒ£ãƒ³ãƒãƒ«åã«ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                    artist_in_video = video_title and artist.lower() in video_title.lower()
                    artist_in_channel = channel_title and artist.lower() in channel_title.lower()

                    if artist_in_video or artist_in_channel:
                        print(f"  âœ… iTunes APIã§ç™ºè¦‹ï¼ˆå‹•ç”»æƒ…å ±ã¨ä¸€è‡´ï¼‰: {artist}")
                        return artist, "exact"

                    matched_artists.append(artist)

                # å‹•ç”»æƒ…å ±ã¨ã®ä¸€è‡´ãŒãªã„å ´åˆã€æœ€åˆã®ä¸€è‡´ã—ãŸã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆã‚’è¿”ã™
                if matched_artists:
                    print(f"  âœ… iTunes APIã§ç™ºè¦‹: {matched_artists[0]}")
                    return matched_artists[0], "exact"

                # éƒ¨åˆ†ä¸€è‡´ã‚‚ãªã„å ´åˆã¯æœ€åˆã®çµæœã‚’å€™è£œã¨ã—ã¦è¿”ã™
                first_artist = results[0].get('artistName', '')
                if first_artist and first_artist.lower() != song_name.lower():
                    print(f"  â„¹ï¸  iTunes APIã§å€™è£œç™ºè¦‹ï¼ˆç¢ºåº¦ä½ï¼‰: {first_artist}")
                    return first_artist, "candidate"

        print(f"  âŒ iTunes APIã§è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        return "", ""

    except Exception as e:
        print(f"  âš ï¸  iTunes API ã‚¨ãƒ©ãƒ¼: {e}")
        return "", ""


def extract_artist_from_title(video_title, song_name):
    """å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåã‚’æŠ½å‡º

    æ§˜ã€…ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¯¾å¿œ:
    - "ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆå - æ›²å"
    - "ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåã€Œæ›²åã€"
    - "ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåã®ã€Œæ›²åã€"
    - "ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆå / æ›²å"
    - "ã€ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåã€‘æ›²å"
    - "æ›²å / ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆå"
    """
    import re

    # ä¸è¦ãªæ¥å°¾è¾ã‚’é™¤å»ã™ã‚‹ãƒªã‚¹ãƒˆ
    suffixes_to_remove = ['å¼¾ã„ã¦ã¿ãŸ', 'æ­Œã£ã¦ã¿ãŸ', 'ã‚’å¼¾ã„ã¦ã¿ãŸ', 'ã‚’æ­Œã£ã¦ã¿ãŸ',
                          'cover', 'Cover', 'COVER', 'Piano', 'piano', 'ãƒ”ã‚¢ãƒ',
                          '(ãƒãƒ³ãƒ†ãƒ­ãƒƒãƒ—ver)', 'ãƒãƒ³ãƒ†ãƒ­ãƒƒãƒ—ver', 'ãƒãƒ³ãƒ†ãƒ­ãƒƒãƒ—']

    # ã‚¿ã‚¤ãƒˆãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    clean_title = video_title
    for suffix in suffixes_to_remove:
        clean_title = clean_title.replace(suffix, '')

    # ãƒ‘ã‚¿ãƒ¼ãƒ³1: "ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆå - æ›²å"
    if ' - ' in clean_title:
        parts = clean_title.split(' - ', 1)
        artist = parts[0].strip()
        # ã€ã€‘ã‚’é™¤å»
        artist = re.sub(r'ã€.*?ã€‘', '', artist).strip()
        if artist and artist not in ['MV', 'Official', 'official']:
            return artist

    # ãƒ‘ã‚¿ãƒ¼ãƒ³2: "ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåã€Œæ›²åã€" ã¾ãŸã¯ "ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåã®ã€Œæ›²åã€"
    if 'ã€Œ' in clean_title:
        parts = clean_title.split('ã€Œ', 1)
        artist = parts[0].strip()
        # "ã®" ã§çµ‚ã‚ã‚‹å ´åˆã¯é™¤å»
        if artist.endswith('ã®'):
            artist = artist[:-1].strip()
        # ã€ã€‘ã‚’é™¤å»
        artist = re.sub(r'ã€.*?ã€‘', '', artist).strip()
        if artist:
            return artist

    # ãƒ‘ã‚¿ãƒ¼ãƒ³2-2: "ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåã€æ›²åã€" (å…¨è§’ã®å¼•ç”¨ç¬¦)
    if 'ã€' in clean_title:
        parts = clean_title.split('ã€', 1)
        artist = parts[0].strip()
        # "ã®" ã§çµ‚ã‚ã‚‹å ´åˆã¯é™¤å»
        if artist.endswith('ã®'):
            artist = artist[:-1].strip()
        # ã€ã€‘ã‚’é™¤å»
        artist = re.sub(r'ã€.*?ã€‘', '', artist).strip()
        if artist and artist not in ['MV', 'Official', 'official']:
            return artist

    # ãƒ‘ã‚¿ãƒ¼ãƒ³3: "ã€MVã€‘ã‚°ãƒ«ãƒ¼ãƒ—åã€æ›²åã€"
    mv_pattern = re.search(r'ã€MVã€‘\s*([^ã€]+)ã€', clean_title)
    if mv_pattern:
        artist = mv_pattern.group(1).strip()
        if artist and artist not in ['MV', 'Official', 'official']:
            return artist

    # ãƒ‘ã‚¿ãƒ¼ãƒ³4: "ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆå / æ›²å"
    if ' / ' in clean_title:
        parts = clean_title.split(' / ')
        # æœ€åˆã®éƒ¨åˆ†ãŒã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåã®å¯èƒ½æ€§ãŒé«˜ã„
        artist = parts[0].strip()
        artist = re.sub(r'ã€.*?ã€‘', '', artist).strip()
        if artist and artist not in ['MV', 'Official', 'official']:
            return artist

    # ãƒ‘ã‚¿ãƒ¼ãƒ³5: "ã€ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåã€‘æ›²å"
    bracket_match = re.search(r'ã€([^ã€‘]+)ã€‘', clean_title)
    if bracket_match:
        artist = bracket_match.group(1).strip()
        if artist and artist not in ['MV', 'Official', 'official', 'Cover', 'cover']:
            return artist

    # ãƒ‘ã‚¿ãƒ¼ãƒ³6: "æ›²å / ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆå" (é€†ãƒ‘ã‚¿ãƒ¼ãƒ³)
    if ' / ' in clean_title:
        parts = clean_title.split(' / ')
        if len(parts) >= 2:
            # 2ç•ªç›®ã®éƒ¨åˆ†ã‚’ãƒã‚§ãƒƒã‚¯
            artist = parts[1].strip()
            artist = re.sub(r'ã€.*?ã€‘', '', artist).strip()
            if artist:
                return artist

    # ãƒ‘ã‚¿ãƒ¼ãƒ³7: ã‚¿ã‚¤ãƒˆãƒ«ãŒæ›²åã¨åŒã˜å ´åˆã€ä½•ã‚‚ã—ãªã„ï¼ˆã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåãªã—ï¼‰
    if clean_title.strip() == song_name:
        return ""

    # æŠ½å‡ºã§ããªã„å ´åˆã¯ç©ºæ–‡å­—åˆ—
    return ""


def save_rankings(rankings):
    """ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’JSONå½¢å¼ã§ä¿å­˜"""
    rankings_output = {}
    for metric_key, ranked_songs in rankings.items():
        rankings_output[metric_key] = [
            {
                'rank': i + 1,
                'song_name': song['song_name'],
                'artist_name': song.get('artist_name', ''),
                'video_id': song['video_id'],
                'video_title': song.get('video_title', ''),
                'release_date': song.get('release_date', ''),  # ML/RLç”¨
                'metrics': {
                    'view_count': song['view_count'],
                    'like_count': song['like_count'],
                    'support_rate': round(song['support_rate'], 2),
                    'comment_count': song['comment_count'],
                    'growth_rate': round(song['growth_rate'], 1),
                    'days_since_published': song['days_since_published']
                },
                'ml_predictions': {  # ML/RLäºˆæ¸¬çµæœ
                    'optimal_posting_datetime': song.get('optimal_posting_datetime', ''),
                    'predicted_view_count': song.get('predicted_view_count', 0),
                    'confidence_score': round(song.get('confidence_score', 0.0), 3)
                }
            }
            for i, song in enumerate(ranked_songs)
        ]

    with open(RANKINGS_FILE, 'w', encoding='utf-8') as f:
        json.dump(rankings_output, f, ensure_ascii=False, indent=2)


def fetch_new_videos():
    """1. æ–°å‹•ç”»fetch"""
    global current_api_key_index, youtube

    # APIã‚­ãƒ¼ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãƒªã‚»ãƒƒãƒˆ
    current_api_key_index = 0
    youtube = build('youtube', 'v3', developerKey=YOUTUBE_API_KEYS[current_api_key_index])

    print("\n" + "="*60)
    print("æ–°å‹•ç”»ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã™")
    print("="*60)
    print(f"ä½¿ç”¨å¯èƒ½ãªAPIã‚­ãƒ¼æ•°: {len(YOUTUBE_API_KEYS)}")

    # æ‰‹å‹•å†å–å¾—ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    print("\nå–å¾—æ–¹æ³•:")
    print("1. ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä½¿ç”¨ï¼ˆ1æ—¥ä»¥å†…ã®ãƒ‡ãƒ¼ã‚¿ã¯å†åˆ©ç”¨ï¼‰")
    print("2. å…¨ã¦å†å–å¾—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ç„¡è¦–ï¼‰")
    choice = input("\né¸æŠ (1/2, ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ=1): ").strip()

    force_refresh = (choice == '2')
    if force_refresh:
        print("\nâš  å…¨ã¦ã®æ›²ã‚’å†å–å¾—ã—ã¾ã™ï¼ˆAPIä½¿ç”¨é‡ã«æ³¨æ„ï¼‰")

        # æ—¢å­˜ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        if os.path.exists(CACHE_FILE):
            os.remove(CACHE_FILE)
            print(f"âœ“ æ—¢å­˜ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã—ãŸ: {CACHE_FILE}")

        # å¤ã„youtube_stats.jsonã‚‚å‰Šé™¤ï¼ˆäº’æ›æ€§ã®ãŸã‚ï¼‰
        old_cache_file = 'youtube_stats.json'
        if os.path.exists(old_cache_file):
            os.remove(old_cache_file)
            print(f"âœ“ å¤ã„ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã—ãŸ: {old_cache_file}")

    # æœªæŠ•ç¨¿ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¸ˆã¿CSVã‚’ä½¿ç”¨
    csv_file = 'filtered data/taiko_server_æœªæŠ•ç¨¿_filtered.csv'
    print(f"\nä½¿ç”¨ã™ã‚‹CSV: {csv_file}")

    if not os.path.exists(csv_file):
        print(f"\nã‚¨ãƒ©ãƒ¼: {csv_file} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        print("å…ˆã«YouTubeãƒãƒ£ãƒ³ãƒãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„:")
        print("  python3 filter_youtube_channel.py")
        return

    songs_data = process_songs_from_csv(csv_file, use_cache=True, force_refresh=force_refresh)

    if not songs_data:
        print("ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        return

    # å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåã‚’æŠ½å‡ºã—ã¦æ›´æ–°
    print("\n" + "="*60)
    print("å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåã‚’æŠ½å‡ºä¸­...")
    print("="*60)
    songs_data = update_artist_names_in_data(songs_data)

    save_cache(songs_data)
    print(f"\nãƒ‡ãƒ¼ã‚¿ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜ã—ã¾ã—ãŸï¼ˆ{len(songs_data)}æ›²ï¼‰")

    rankings = create_rankings(songs_data)
    save_rankings(rankings)
    print(f"ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’ä¿å­˜ã—ã¾ã—ãŸ")


def manage_tasks():
    """2. ã‚¿ã‚¹ã‚¯ç®¡ç†"""
    if not os.path.exists(RANKINGS_FILE):
        print("\nã‚¨ãƒ©ãƒ¼: ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚å…ˆã«ã€Œ1. æ–°å‹•ç”»fetchã€ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        return

    with open(RANKINGS_FILE, 'r', encoding='utf-8') as f:
        rankings = json.load(f)

    overall = rankings.get('overall', [])
    if not overall:
        print("\nç·åˆãƒ©ãƒ³ã‚­ãƒ³ã‚°ãŒç©ºã§ã™ã€‚")
        return

    # ã‚¿ã‚¹ã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
    tasks = load_tasks()

    while True:
        print("\n" + "="*60)
        print("ã‚¿ã‚¹ã‚¯ç®¡ç† - ç·åˆãƒ©ãƒ³ã‚­ãƒ³ã‚°")
        print("="*60)

        for i, item in enumerate(overall[:10], 1):
            song_name = item['song_name']
            task_status = tasks.get(song_name, {})
            recording = "âœ“" if task_status.get('recording') else "ã€€"
            editing = "âœ“" if task_status.get('editing') else "ã€€"
            posting = "âœ“" if task_status.get('posting') else "ã€€"

            print(f"{i:2d}. {song_name}")
            print(f"    [{recording}] ç”»é¢åéŒ²  [{editing}] ç·¨é›†  [{posting}] æŠ•ç¨¿")

        print("\næ“ä½œ:")
        print("æ›²ç•ªå·ã‚’å…¥åŠ›ã—ã¦ã‚¿ã‚¹ã‚¯ã‚’æ›´æ–° (ä¾‹: 1)")
        print("0: æˆ»ã‚‹")

        choice = input("\né¸æŠ: ").strip()

        if choice == '0':
            break

        try:
            idx = int(choice) - 1
            if 0 <= idx < len(overall):
                update_task(overall[idx]['song_name'], tasks)
        except ValueError:
            print("ç„¡åŠ¹ãªå…¥åŠ›ã§ã™")


def load_tasks():
    """ã‚¿ã‚¹ã‚¯ã‚’èª­ã¿è¾¼ã‚€"""
    if os.path.exists(TASKS_FILE):
        with open(TASKS_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}


def save_tasks(tasks):
    """ã‚¿ã‚¹ã‚¯ã‚’ä¿å­˜"""
    with open(TASKS_FILE, 'w', encoding='utf-8') as f:
        json.dump(tasks, f, ensure_ascii=False, indent=2)


def update_task(song_name, tasks):
    """ã‚¿ã‚¹ã‚¯ã‚’æ›´æ–°"""
    if song_name not in tasks:
        tasks[song_name] = {'recording': False, 'editing': False, 'posting': False}

    task = tasks[song_name]

    print(f"\n{song_name} ã®ã‚¿ã‚¹ã‚¯:")
    print(f"1. ç”»é¢åéŒ² [{'âœ“' if task['recording'] else ' '}]")
    print(f"2. ç·¨é›† [{'âœ“' if task['editing'] else ' '}]")
    print(f"3. æŠ•ç¨¿ [{'âœ“' if task['posting'] else ' '}]")
    print("4. å…¨ã¦ã‚¯ãƒªã‚¢")

    choice = input("ãƒˆã‚°ãƒ«ã™ã‚‹é …ç›® (1-4): ").strip()

    if choice == '1':
        task['recording'] = not task['recording']
    elif choice == '2':
        task['editing'] = not task['editing']
    elif choice == '3':
        task['posting'] = not task['posting']
    elif choice == '4':
        task['recording'] = False
        task['editing'] = False
        task['posting'] = False

    save_tasks(tasks)
    print("ã‚¿ã‚¹ã‚¯ã‚’æ›´æ–°ã—ã¾ã—ãŸ")


def export_csv():
    """3. CSVå‡ºåŠ›"""
    if not os.path.exists(RANKINGS_FILE):
        print("\nã‚¨ãƒ©ãƒ¼: ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚å…ˆã«ã€Œ1. æ–°å‹•ç”»fetchã€ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        return

    print("\n" + "="*60)
    print("CSVå‡ºåŠ›")
    print("="*60)
    print("1. Overall (ç·åˆãƒ©ãƒ³ã‚­ãƒ³ã‚°)")
    print("2. Popularity (äººæ°—åº¦)")
    print("3. Support Rate (æ”¯æŒç‡)")
    print("4. Engagement (ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆ)")
    print("5. Growth Rate (æ€¥ä¸Šæ˜‡åº¦)")
    print("6. All (çµ±åˆç‰ˆ)")
    print("7. ğŸ”„ å…¨ã¦æ›´æ–°ã—ã¦CSVå‡ºåŠ›ï¼ˆãƒ©ãƒ³ã‚­ãƒ³ã‚°å†è¨ˆç®—ï¼‰")
    print("0. æˆ»ã‚‹")

    choice = input("\né¸æŠ: ").strip()

    ranking_types = {
        '1': 'overall',
        '2': 'popularity',
        '3': 'support_rate',
        '4': 'engagement',
        '5': 'growth_rate'
    }

    if choice in ranking_types:
        export_single_ranking(ranking_types[choice])
    elif choice == '6':
        export_all_rankings()
    elif choice == '7':
        update_and_export_all()
    elif choice != '0':
        print("ç„¡åŠ¹ãªé¸æŠã§ã™")


def export_single_ranking(ranking_type):
    """å€‹åˆ¥ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’CSVã«å‡ºåŠ›"""
    with open(RANKINGS_FILE, 'r', encoding='utf-8') as f:
        rankings = json.load(f)

    if ranking_type not in rankings:
        print(f"ã‚¨ãƒ©ãƒ¼: {ranking_type} ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return

    filename = f"ranking_{ranking_type}.csv"

    with open(filename, 'w', encoding='utf-8', newline='') as f:
        writer = csv.writer(f)
        writer.writerow([
            'é †ä½', 'release_date', 'ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆå', 'æ›²å', 'å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«', 'Video ID', 'å†ç”Ÿæ•°', 'é«˜è©•ä¾¡æ•°',
            'æ”¯æŒç‡(%)', 'ã‚³ãƒ¡ãƒ³ãƒˆæ•°', 'æ€¥ä¸Šæ˜‡åº¦(views/day)', 'å…¬é–‹æ—¥æ•°',
            'æœ€é©æŠ•ç¨¿æ—¥æ™‚', 'äºˆæ¸¬è¦–è´æ•°', 'ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢'
        ])

        for item in rankings[ranking_type]:
            ml_pred = item.get('ml_predictions', {})
            writer.writerow([
                item['rank'],
                item.get('release_date', ''),
                item.get('artist_name', ''),
                item['song_name'],
                item.get('video_title', ''),
                item['video_id'],
                item['metrics']['view_count'],
                item['metrics']['like_count'],
                item['metrics']['support_rate'],
                item['metrics']['comment_count'],
                item['metrics']['growth_rate'],
                item['metrics']['days_since_published'],
                ml_pred.get('optimal_posting_datetime', ''),
                ml_pred.get('predicted_view_count', ''),
                ml_pred.get('confidence_score', '')
            ])

    print(f"\n{filename} ã‚’ä½œæˆã—ã¾ã—ãŸ ({len(rankings[ranking_type])}æ›²)")


def export_all_rankings():
    """å…¨ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’çµ±åˆã—ã¦CSVã«å‡ºåŠ›"""
    with open(RANKINGS_FILE, 'r', encoding='utf-8') as f:
        rankings = json.load(f)

    # TaikoGameã®IDæƒ…å ±ã‚’èª­ã¿è¾¼ã¿
    song_id_map = {}
    taiko_csv_path = 'RAW DATA/taiko_server_raw.csv'
    if os.path.exists(taiko_csv_path):
        with open(taiko_csv_path, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                song_name = row.get('song_name', '').strip()
                song_id = row.get('id', '').strip()
                if song_name and song_id:
                    song_id_map[song_name] = song_id
        print(f"  ğŸ“ TaikoGame IDæƒ…å ±: {len(song_id_map)}æ›²åˆ†ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
    else:
        print(f"  âš  è­¦å‘Š: {taiko_csv_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚IDã‚«ãƒ©ãƒ ã¯ç©ºã«ãªã‚Šã¾ã™ã€‚")

    all_songs = {}

    for metric_key in ['popularity', 'support_rate', 'engagement', 'growth_rate', 'overall']:
        if metric_key not in rankings:
            continue

        for item in rankings[metric_key]:
            song_name = item['song_name']
            if song_name not in all_songs:
                all_songs[song_name] = {
                    'artist_name': item.get('artist_name', ''),
                    'video_title': item.get('video_title', ''),
                    'video_id': item['video_id'],
                    'release_date': item.get('release_date', ''),  # ML/RLç”¨
                    'metrics': item['metrics'],
                    'ml_predictions': item.get('ml_predictions', {}),  # ML/RLäºˆæ¸¬çµæœ
                    'ranks': {}
                }
            all_songs[song_name]['ranks'][metric_key] = item['rank']

    filename = 'ranking_all.csv'

    with open(filename, 'w', encoding='utf-8', newline='') as f:
        writer = csv.writer(f)
        # IDã‚«ãƒ©ãƒ ã‚’å…ˆé ­ã«è¿½åŠ ã€ML/RLåˆ—ã‚’è¿½åŠ 
        writer.writerow([
            'id', 'release_date', 'ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆå', 'æ›²å', 'å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«', 'Video ID', 'å†ç”Ÿæ•°', 'é«˜è©•ä¾¡æ•°', 'æ”¯æŒç‡(%)',
            'ã‚³ãƒ¡ãƒ³ãƒˆæ•°', 'æ€¥ä¸Šæ˜‡åº¦(views/day)', 'å…¬é–‹æ—¥æ•°',
            'äººæ°—åº¦é †ä½', 'æ”¯æŒç‡é †ä½', 'ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆé †ä½', 'æ€¥ä¸Šæ˜‡åº¦é †ä½', 'ç·åˆé †ä½',
            'æœ€é©æŠ•ç¨¿æ—¥æ™‚', 'äºˆæ¸¬è¦–è´æ•°', 'ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢'
        ])

        sorted_songs = sorted(
            all_songs.items(),
            key=lambda x: x[1]['ranks'].get('overall', 999)
        )

        matched_count = 0
        for song_name, data in sorted_songs:
            song_id = song_id_map.get(song_name, '')
            if song_id:
                matched_count += 1

            ml_pred = data.get('ml_predictions', {})
            writer.writerow([
                song_id,  # æ›²IDã‚’å…ˆé ­ã«è¿½åŠ 
                data.get('release_date', ''),  # release_dateè¿½åŠ 
                data.get('artist_name', ''),
                song_name,
                data.get('video_title', ''),
                data['video_id'],
                data['metrics']['view_count'],
                data['metrics']['like_count'],
                data['metrics']['support_rate'],
                data['metrics']['comment_count'],
                data['metrics']['growth_rate'],
                data['metrics']['days_since_published'],
                data['ranks'].get('popularity', '-'),
                data['ranks'].get('support_rate', '-'),
                data['ranks'].get('engagement', '-'),
                data['ranks'].get('growth_rate', '-'),
                data['ranks'].get('overall', '-'),
                ml_pred.get('optimal_posting_datetime', ''),  # ML/RL: æœ€é©æŠ•ç¨¿æ—¥æ™‚
                ml_pred.get('predicted_view_count', ''),  # ML/RL: äºˆæ¸¬è¦–è´æ•°
                ml_pred.get('confidence_score', '')  # ML/RL: ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢
            ])

    print(f"\n{filename} ã‚’ä½œæˆã—ã¾ã—ãŸ (å…¨{len(all_songs)}æ›²)")
    print(f"  âœ“ TaikoGame IDã¨ãƒãƒƒãƒãƒ³ã‚°: {matched_count}/{len(all_songs)}æ›²")
    if matched_count < len(all_songs):
        print(f"  âš  {len(all_songs) - matched_count}æ›²ã®IDãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")


def update_and_export_all():
    """ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’å†è¨ˆç®—ã—ã¦ã‹ã‚‰å…¨CSVã‚’å‡ºåŠ›"""
    print("\n" + "="*60)
    print("ğŸ”„ ãƒ©ãƒ³ã‚­ãƒ³ã‚°å†è¨ˆç®— & å…¨CSVå‡ºåŠ›")
    print("="*60)
    print("æœ€æ–°ã®youtube_stats.jsonã‹ã‚‰ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’å†è¨ˆç®—ã—ã€")
    print("å…¨ã¦ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°ã—ã¾ã™ã€‚")
    print("="*60)

    confirm = input("\nå®Ÿè¡Œã—ã¾ã™ã‹ï¼Ÿ (yes/no): ").strip().lower()

    if confirm != 'yes':
        print("ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ")
        return

    # youtube_stats.jsonã®å­˜åœ¨ç¢ºèª
    if not os.path.exists(CACHE_FILE):
        print(f"\nã‚¨ãƒ©ãƒ¼: {CACHE_FILE} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return

    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’èª­ã¿è¾¼ã¿
    print(f"\nğŸ“‚ {CACHE_FILE} ã‚’èª­ã¿è¾¼ã¿ä¸­...")
    songs_data = load_cache()
    print(f"âœ“ {len(songs_data)}æ›²ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")

    # ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’å†è¨ˆç®—
    print("\nğŸ“Š ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’å†è¨ˆç®—ä¸­...")
    rankings = create_rankings(songs_data)
    save_rankings(rankings)
    print("âœ“ ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’ä¿å­˜ã—ã¾ã—ãŸ")

    # å…¨ã¦ã®CSVã‚’å‡ºåŠ›
    print("\nğŸ“ CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆä¸­...")

    # å„ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚¿ã‚¤ãƒ—ã®CSVã‚’ä½œæˆ
    csv_count = 0
    for ranking_type in ['popularity', 'support_rate', 'engagement', 'growth_rate', 'overall']:
        if ranking_type in rankings:
            export_single_ranking(ranking_type)
            csv_count += 1

    # çµ±åˆç‰ˆCSVã‚’ä½œæˆ
    export_all_rankings()
    csv_count += 1

    print("\n" + "="*60)
    print(f"âœ… å®Œäº†ï¼ {csv_count}å€‹ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°ã—ã¾ã—ãŸ")
    print("="*60)


def scrape_titles():
    """4. ã‚¿ã‚¤ãƒˆãƒ«ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ï¼ˆAPIä¸è¦ï¼‰"""
    print("\n" + "="*60)
    print("ã‚¿ã‚¤ãƒˆãƒ«ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°")
    print("="*60)
    print("1. å…¨æ›²ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°")
    print("2. æŒ‡å®šæ›²æ•°ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°")
    print("0. æˆ»ã‚‹")

    choice = input("\né¸æŠ: ").strip()

    if choice == '1':
        import subprocess
        print("\nå…¨æ›²ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã—ã¾ã™...")
        subprocess.run(['python3', 'scrape_titles.py'])
    elif choice == '2':
        limit = input("å‡¦ç†ã™ã‚‹æ›²æ•°ã‚’å…¥åŠ›: ").strip()
        try:
            limit_num = int(limit)
            import subprocess
            print(f"\næœ€åˆã®{limit_num}æ›²ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã—ã¾ã™...")
            subprocess.run(['python3', 'scrape_titles_limited.py', str(limit_num)])
        except ValueError:
            print("ç„¡åŠ¹ãªæ•°å€¤ã§ã™")
    elif choice != '0':
        print("ç„¡åŠ¹ãªé¸æŠã§ã™")


def generate_videos():
    """5. å‹•ç”»ç”Ÿæˆ"""
    print("\n" + "="*60)
    print("å‹•ç”»ç”Ÿæˆ")
    print("="*60)
    print("1. å˜ä¸€å‹•ç”»ç”Ÿæˆ")
    print("2. ãƒãƒƒãƒå‹•ç”»ç”Ÿæˆï¼ˆCSVã‹ã‚‰ï¼‰")
    print("0. æˆ»ã‚‹")

    choice = input("\né¸æŠ: ").strip()

    if choice == '1':
        from batch_video_generator_layers import LayerBasedBatchVideoGenerator

        artist = input("ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆå: ").strip()
        song = input("æ›²å: ").strip()

        # ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåã‚’å«ã‚ã‚‹ã‹ç¢ºèª
        include_artist_input = input("ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåã‚’å«ã‚ã¾ã™ã‹ï¼Ÿ (y/n, ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: y): ").strip().lower()
        include_artist = include_artist_input != 'n'

        # ãƒ™ãƒ¼ã‚¹å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡å®š
        print("\nãƒ™ãƒ¼ã‚¹å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡å®šã—ã¦ãã ã•ã„")
        print("ï¼ˆè¤‡æ•°æŒ‡å®šã™ã‚‹å ´åˆã¯ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã€ä¾‹: video1.mp4,video2.mp4ï¼‰")
        print("ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: output/{æ›²å}.mp4 ã¾ãŸã¯ base.mp4ï¼‰")
        base_video_input = input("ãƒ™ãƒ¼ã‚¹å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«: ").strip()

        base_videos = []
        if base_video_input:
            # ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§è¤‡æ•°ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
            base_videos = [v.strip() for v in base_video_input.split(',') if v.strip()]

            # ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
            for video in base_videos:
                if not os.path.exists(video):
                    print(f"è­¦å‘Š: {video} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        output_dir = 'output_videos'

        # å‹•ç”»ç”Ÿæˆ
        generator = LayerBasedBatchVideoGenerator('template.json', 'base.mp4')

        if not base_videos:
            # ãƒ™ãƒ¼ã‚¹å‹•ç”»ãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®å‹•ä½œ
            print(f"\nå‹•ç”»ã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™...")
            video_path = generator.generate_single_video(
                artist, song, output_dir,
                include_artist=include_artist
            )
            if video_path:
                print(f"\nâœ“ å‹•ç”»ç”Ÿæˆå®Œäº†: {video_path}")
        else:
            # è¤‡æ•°ã®ãƒ™ãƒ¼ã‚¹å‹•ç”»ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã€ãã‚Œãã‚Œã§ç”Ÿæˆ
            print(f"\n{len(base_videos)}å€‹ã®ãƒ™ãƒ¼ã‚¹å‹•ç”»ã§ç”Ÿæˆã—ã¾ã™")
            for i, base_video in enumerate(base_videos, 1):
                if not os.path.exists(base_video):
                    print(f"ã‚¹ã‚­ãƒƒãƒ—: {base_video}ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼‰")
                    continue

                # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã«ãƒ™ãƒ¼ã‚¹å‹•ç”»åã‚’å«ã‚ã‚‹
                base_name = os.path.splitext(os.path.basename(base_video))[0]
                video_name = f"{artist}_{song}_{base_name}.mp4"

                print(f"\n[{i}/{len(base_videos)}] ãƒ™ãƒ¼ã‚¹å‹•ç”»: {base_video}")
                video_path = generator.generate_single_video(
                    artist, song, output_dir,
                    video_name=video_name,
                    base_video_override=base_video,
                    include_artist=include_artist
                )
                if video_path:
                    print(f"âœ“ å‹•ç”»ç”Ÿæˆå®Œäº†: {video_path}")

    elif choice == '2':
        csv_file = input("CSVãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ranking_all.csv): ").strip()
        if not csv_file:
            csv_file = 'ranking_all.csv'

        if not os.path.exists(csv_file):
            print(f"ã‚¨ãƒ©ãƒ¼: {csv_file} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return

        import subprocess
        print(f"\n{csv_file}ã‹ã‚‰å‹•ç”»ã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™...")
        subprocess.run(['python3', 'batch_video_generator_layers.py', csv_file])
    elif choice != '0':
        print("ç„¡åŠ¹ãªé¸æŠã§ã™")


def refetch_with_artists():
    """6. ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåã®ã¿æ›´æ–°ï¼ˆAPIä¸è¦ï¼‰"""
    print("\n" + "="*60)
    print("ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåã®ã¿æ›´æ–°ï¼ˆYouTube APIä¸ä½¿ç”¨ï¼‰")
    print("="*60)
    print("æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåã®ã¿ã‚’æ›´æ–°ã—ã¾ã™")
    print("ï¼ˆå‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«ã€ãƒãƒ£ãƒ³ãƒãƒ«åã€å†ç”Ÿæ•°ãªã©ã¯å¤‰æ›´ã•ã‚Œã¾ã›ã‚“ï¼‰")

    confirm = input("\nå®Ÿè¡Œã—ã¾ã™ã‹ï¼Ÿ (yes/no): ").strip().lower()

    if confirm == 'yes':
        import subprocess
        subprocess.run(['python3', 'update_artists_only.py'])
    else:
        print("ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ")


def search_artist_itunes():
    """7. iTunes APIã§å…¨æ›²ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆæ›´æ–°"""
    print("\n" + "="*60)
    print("iTunes APIã§å…¨æ›²ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆæ›´æ–°")
    print("="*60)
    print("âš ï¸  å…¨ã¦ã®æ›²ã‚’iTunes APIã§æ¤œç´¢ã—ã¦ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåã‚’æ›´æ–°ã—ã¾ã™")

    confirm = input("\nå®Ÿè¡Œã—ã¾ã™ã‹ï¼Ÿ (yes/no): ").strip().lower()

    if confirm == 'yes':
        import subprocess
        subprocess.run(['python3', 'update_artists_itunes.py'])
    else:
        print("ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ")


def fetch_taikogame_to_csv():
    """8. TaikoGameãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ»CSVä¿å­˜"""
    print("\n" + "="*60)
    print("TaikoGameã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰å…¨ãƒ‡ãƒ¼ã‚¿å–å¾—")
    print("="*60)

    print("\nTaikoGameã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰å…¨ã¦ã®æ›²ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦CSVã«ä¿å­˜ã—ã¾ã™")
    print("ï¼ˆå…¨ã¦ã®ãƒªãƒªãƒ¼ã‚¹çŠ¶æ…‹ã®æ›²ã‚’å«ã‚€ï¼‰")

    confirm = input("\nå®Ÿè¡Œã—ã¾ã™ã‹ï¼Ÿ (yes/no): ").strip().lower()

    if confirm != 'yes':
        print("ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ")
        return

    # TaikoGameã‹ã‚‰å…¨ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    print("\n" + "="*60)
    taikogame_artists, taikogame_full_data = fetch_taikogame_artists()

    if not taikogame_full_data:
        print("\nâš  ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
        return

    # CSVã«ä¿å­˜
    output_file = 'RAW DATA/taiko_server_raw.csv'

    # RAW DATAãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    os.makedirs('RAW DATA', exist_ok=True)

    fieldnames = [
        'id',
        'release_date',
        'title',
        'furigana',
        'edit',
        'tags',
        'data',
        'jasrac_code',
        'difficulty',
        'youtube',
        'download',
        'release_status',
        'song_name',
        'artist_name'
    ]

    with open(output_file, 'w', encoding='utf-8', newline='') as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(taikogame_full_data)

    print(f"\nâœ“ {output_file} ã«ä¿å­˜ã—ã¾ã—ãŸ")
    print(f"  å–å¾—æ›²æ•°: {len(taikogame_full_data)}æ›²")
    print("="*60)


def ml_rl_schedule_optimization():
    """10. ML/RLã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æœ€é©åŒ–"""
    print("\n" + "="*60)
    print("ğŸ¤– ML/RLã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æœ€é©åŒ–")
    print("="*60)

    # å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    try:
        from feature_engineering import FeatureEngineer
        from ml_scheduler import ViewCountPredictor
        from rl_scheduler import optimize_schedule
    except ImportError as e:
        print(f"\nã‚¨ãƒ©ãƒ¼: å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã§ãã¾ã›ã‚“: {e}")
        print("requirements.txtã®ä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„:")
        print("  pip install -r requirements.txt")
        return

    # 1. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    print("\n" + "-"*60)
    print("ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿")
    print("-"*60)

    if not os.path.exists(RANKINGS_FILE):
        print(f"ã‚¨ãƒ©ãƒ¼: {RANKINGS_FILE} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        print("å…ˆã«ã‚ªãƒ—ã‚·ãƒ§ãƒ³1ã§æ–°å‹•ç”»fetchã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
        return

    with open(RANKINGS_FILE, 'r', encoding='utf-8') as f:
        rankings = json.load(f)

    # å…¨æ›²ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆoverallãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‹ã‚‰ï¼‰
    if 'overall' not in rankings:
        print("ã‚¨ãƒ©ãƒ¼: overallãƒ©ãƒ³ã‚­ãƒ³ã‚°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return

    songs_data = []
    for item in rankings['overall']:
        song = {
            'song_name': item['song_name'],
            'artist_name': item.get('artist_name', ''),
            'video_id': item['video_id'],
            'release_date': item.get('release_date', ''),
            'view_count': item['metrics']['view_count'],
            'like_count': item['metrics']['like_count'],
            'comment_count': item['metrics']['comment_count'],
            'support_rate': item['metrics']['support_rate'],
            'growth_rate': item['metrics']['growth_rate'],
            'days_since_published': item['metrics']['days_since_published']
        }
        songs_data.append(song)

    print(f"âœ“ {len(songs_data)}æ›²ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")

    # TaikoGameãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ï¼ˆã‚¿ã‚°æƒ…å ±ç”¨ï¼‰
    taiko_data_map = {}
    taiko_csv = 'filtered data/taiko_server_æœªæŠ•ç¨¿_filtered.csv'
    if os.path.exists(taiko_csv):
        try:
            import csv
            with open(taiko_csv, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    song_name = row.get('song_name', '').strip()
                    if song_name:
                        taiko_data_map[song_name] = row
            print(f"âœ“ TaikoGameãƒ‡ãƒ¼ã‚¿ {len(taiko_data_map)}æ›²ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
        except Exception as e:
            print(f"è­¦å‘Š: TaikoGameãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

    # 2. ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
    print("\n" + "-"*60)
    print("ã‚¹ãƒ†ãƒƒãƒ—2: ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°")
    print("-"*60)

    engineer = FeatureEngineer()
    target_datetime = datetime.datetime.now()

    try:
        X, y, feature_names = engineer.prepare_training_data(
            songs_data,
            taiko_data_map,
            target_datetime
        )
        print(f"âœ“ ç‰¹å¾´é‡ã‚’ç”Ÿæˆã—ã¾ã—ãŸ")
        print(f"  - ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(X)}")
        print(f"  - ç‰¹å¾´é‡æ•°: {len(feature_names)}")
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼: ç‰¹å¾´é‡ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()
        return

    # 3. ML View Predictorè¨“ç·´
    print("\n" + "-"*60)
    print("ã‚¹ãƒ†ãƒƒãƒ—3: Deep Learningè¦–è´æ•°äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«è¨“ç·´")
    print("-"*60)

    try:
        predictor = ViewCountPredictor(input_dim=X.shape[1])

        # ãƒ¢ãƒ‡ãƒ«è¨“ç·´
        predictor.train(
            X, y,
            epochs=100,
            validation_split=0.2,
            use_augmentation=True,
            verbose=1
        )

        # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
        predictor.save()

        print("\nâœ“ MLäºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ãŒå®Œäº†ã—ã¾ã—ãŸ")

    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼: MLè¨“ç·´ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()
        return

    # 4. RLã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æœ€é©åŒ–
    print("\n" + "-"*60)
    print("ã‚¹ãƒ†ãƒƒãƒ—4: Reinforcement Learningã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æœ€é©åŒ–")
    print("-"*60)

    try:
        # æœ€é©ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ç”Ÿæˆ
        optimized_schedule = optimize_schedule(
            songs_data=songs_data,
            view_predictor=predictor,
            num_episodes=500
        )

        print(f"\nâœ“ æœ€é©ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {len(optimized_schedule)}æ›²")

    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼: RLæœ€é©åŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()
        return

    # 5. çµæœã‚’åæ˜ 
    print("\n" + "-"*60)
    print("ã‚¹ãƒ†ãƒƒãƒ—5: çµæœã‚’rankings.jsonã«åæ˜ ")
    print("-"*60)

    # æ›²å -> MLäºˆæ¸¬çµæœã®ãƒãƒƒãƒ”ãƒ³ã‚°
    ml_results_map = {}
    for song, posting_datetime, predicted_views, confidence in optimized_schedule:
        ml_results_map[song['song_name']] = {
            'optimal_posting_datetime': posting_datetime.strftime('%Y-%m-%d %H:%M:%S'),
            'predicted_view_count': int(predicted_views),
            'confidence_score': float(confidence)
        }

    # rankings.jsonã‚’æ›´æ–°
    updated_count = 0
    for metric_key in rankings:
        for item in rankings[metric_key]:
            song_name = item['song_name']
            if song_name in ml_results_map:
                # MLäºˆæ¸¬çµæœã‚’è¿½åŠ 
                if 'ml_predictions' not in item:
                    item['ml_predictions'] = {}
                item['ml_predictions'].update(ml_results_map[song_name])

                # song_dataè‡ªä½“ã«ã‚‚è¿½åŠ ï¼ˆå¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ï¼‰
                item['optimal_posting_datetime'] = ml_results_map[song_name]['optimal_posting_datetime']
                item['predicted_view_count'] = ml_results_map[song_name]['predicted_view_count']
                item['confidence_score'] = ml_results_map[song_name]['confidence_score']
                updated_count += 1

    # rankings.jsonã‚’ä¿å­˜
    with open(RANKINGS_FILE, 'w', encoding='utf-8') as f:
        json.dump(rankings, f, ensure_ascii=False, indent=2)

    print(f"âœ“ {RANKINGS_FILE} ã‚’æ›´æ–°ã—ã¾ã—ãŸï¼ˆ{updated_count}ä»¶ï¼‰")

    # 6. çµæœã‚µãƒãƒªãƒ¼è¡¨ç¤º
    print("\n" + "="*60)
    print("ğŸ“Š æœ€é©åŒ–çµæœã‚µãƒãƒªãƒ¼")
    print("="*60)

    total_predicted_views = sum(predicted_views for _, _, predicted_views, _ in optimized_schedule)
    avg_confidence = sum(confidence for _, _, _, confidence in optimized_schedule) / len(optimized_schedule)

    print(f"\nå‡¦ç†æ›²æ•°: {len(optimized_schedule)}æ›²")
    print(f"ç·äºˆæ¸¬è¦–è´å›æ•°: {total_predicted_views:,.0f} views")
    print(f"å¹³å‡ä¿¡é ¼åº¦: {avg_confidence*100:.1f}%")

    # ä»Šé€±ã®æŠ•ç¨¿ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆä¸Šä½10ä»¶ï¼‰
    print("\nä»Šé€±ã®æ¨å¥¨æŠ•ç¨¿ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆäºˆæ¸¬è¦–è´æ•°ãƒˆãƒƒãƒ—10ï¼‰:")
    sorted_schedule = sorted(
        optimized_schedule,
        key=lambda x: x[2],  # predicted_views is the 3rd element
        reverse=True
    )[:10]

    for i, (song, posting_datetime, predicted_views, confidence) in enumerate(sorted_schedule, 1):
        print(f"  {i}. {posting_datetime.strftime('%Y-%m-%d %H:%M')} - ã€Œ{song['song_name']}ã€{song.get('artist_name', '')}")
        print(f"     äºˆæ¸¬: {predicted_views:,.0f} views (ä¿¡é ¼åº¦: {confidence*100:.0f}%)")

    # CSVå†å‡ºåŠ›ã‚’æ¨å¥¨
    print("\n" + "="*60)
    print("ğŸ’¡ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print("  - ã‚ªãƒ—ã‚·ãƒ§ãƒ³3ã§CSVã‚’å†å‡ºåŠ›ã™ã‚‹ã¨ã€ML/RLçµæœãŒåæ˜ ã•ã‚Œã¾ã™")
    print("="*60)


def open_template():
    """9. ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç·¨é›†"""
    import subprocess

    editor_script = 'template_editor_layers.py'

    if not os.path.exists(editor_script):
        print(f"\nã‚¨ãƒ©ãƒ¼: {editor_script} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return

    print("\n" + "="*60)
    print("ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚¨ãƒ‡ã‚£ã‚¿ã‚’èµ·å‹•ã—ã¾ã™")
    print("="*60)

    try:
        subprocess.run(['python3', editor_script])
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼: ã‚¨ãƒ‡ã‚£ã‚¿ã‚’èµ·å‹•ã§ãã¾ã›ã‚“ã§ã—ãŸ - {e}")


def main():
    """ãƒ¡ã‚¤ãƒ³ãƒ¡ãƒ‹ãƒ¥ãƒ¼"""
    while True:
        print("\n" + "="*60)
        print("YouTubeæ›²ãƒã‚¤ãƒ©ãƒªãƒ†ã‚£åˆ†æãƒ„ãƒ¼ãƒ«")
        print("="*60)
        print("1. æ–°å‹•ç”»fetchï¼ˆYouTube APIï¼‰")
        print("2. ã‚¿ã‚¹ã‚¯ç®¡ç†")
        print("3. CSVå‡ºåŠ›")
        print("4. ã‚¿ã‚¤ãƒˆãƒ«ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ï¼ˆAPIä¸è¦ï¼‰")
        print("5. å‹•ç”»ç”Ÿæˆ")
        print("6. ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåã®ã¿æ›´æ–°ï¼ˆAPIä¸è¦ï¼‰")
        print("7. iTunes APIã§å…¨æ›²ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆæ›´æ–°")
        print("8. TaikoGameãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ»CSVä¿å­˜")
        print("9. ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç·¨é›†")
        print("10. ğŸ¤– ML/RLã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æœ€é©åŒ–")
        print("0. çµ‚äº†")

        choice = input("\né¸æŠ: ").strip()

        if choice == '1':
            fetch_new_videos()
        elif choice == '2':
            manage_tasks()
        elif choice == '3':
            export_csv()
        elif choice == '4':
            scrape_titles()
        elif choice == '5':
            generate_videos()
        elif choice == '6':
            refetch_with_artists()
        elif choice == '7':
            search_artist_itunes()
        elif choice == '8':
            fetch_taikogame_to_csv()
        elif choice == '9':
            open_template()
        elif choice == '10':
            ml_rl_schedule_optimization()
        elif choice == '0':
            print("\nçµ‚äº†ã—ã¾ã™")
            break
        else:
            print("\nç„¡åŠ¹ãªé¸æŠã§ã™ã€‚0-10 ã®ã„ãšã‚Œã‹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")


if __name__ == '__main__':
    main()
