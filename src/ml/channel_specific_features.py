#!/usr/bin/env python3
"""
ãƒãƒ£ãƒ³ãƒãƒ«å›ºæœ‰ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ´»ç”¨ã—ãŸç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°æ‹¡å¼µ

YouTube API ã‹ã‚‰å–å¾—ã—ãŸãƒãƒ£ãƒ³ãƒãƒ«å±¥æ­´ãƒ‡ãƒ¼ã‚¿ (@taiko_de_hit_song) ã«åŸºã¥ã„ã¦
æœ€é©ãªæŠ•ç¨¿æ™‚é–“ã‚’å­¦ç¿’ã™ã‚‹è¿½åŠ ç‰¹å¾´é‡ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
"""

import pandas as pd
import numpy as np
from datetime import datetime


class ChannelSpecificFeatureEngineer:
    """
    @taiko_de_hit_song ãƒãƒ£ãƒ³ãƒãƒ«ç‰¹æœ‰ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç‰¹å¾´é‡åŒ–

    channel_history.csv ã‹ã‚‰æŠ½å‡ºã•ã‚ŒãŸãƒ‘ã‚¿ãƒ¼ãƒ³:
    - æ›œæ—¥åˆ¥å¹³å‡è¦–è´æ•°
    - æ™‚é–“å¸¯åˆ¥å¹³å‡è¦–è´æ•°
    - ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»ã®ç‰¹æ€§
    """

    def __init__(self, channel_history_path='channel_history_clean.csv'):
        """
        Args:
            channel_history_path: ãƒãƒ£ãƒ³ãƒãƒ«å±¥æ­´CSVã®ãƒ‘ã‚¹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: åºƒå‘Šé™¤å¤–ç‰ˆï¼‰
        """
        self.channel_history_path = channel_history_path
        self.channel_data = None
        self.day_of_week_stats = None
        self.hour_stats = None

        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¨çµ±è¨ˆè¨ˆç®—
        self._load_channel_history()
        self._calculate_statistics()

    def _load_channel_history(self):
        """ãƒãƒ£ãƒ³ãƒãƒ«å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        try:
            self.channel_data = pd.read_csv(self.channel_history_path)
            print(f"âœ“ ãƒãƒ£ãƒ³ãƒãƒ«å±¥æ­´ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(self.channel_data)}ä»¶")
        except FileNotFoundError:
            print(f"âš  {self.channel_history_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆçµ±è¨ˆã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            self.channel_data = None

    def _calculate_statistics(self):
        """æ›œæ—¥åˆ¥ãƒ»æ™‚é–“å¸¯åˆ¥ã®çµ±è¨ˆã‚’è¨ˆç®—"""
        if self.channel_data is None:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆçµ±è¨ˆï¼ˆå®Ÿæ¸¬å€¤ãƒ™ãƒ¼ã‚¹ï¼‰
            self.day_of_week_stats = {
                0: 1870,  # æœˆæ›œ
                1: 1672,  # ç«æ›œ
                2: 1711,  # æ°´æ›œ
                3: 3203,  # æœ¨æ›œ (æœ€é«˜)
                4: 1533,  # é‡‘æ›œ
                5: 1981,  # åœŸæ›œ
                6: 2157   # æ—¥æ›œ
            }

            self.hour_stats = {
                1: 1859, 2: 1343, 3: 1813, 4: 1049, 5: 2174,
                6: 2413, 7: 1345, 8: 2125, 9: 1985, 12: 681,
                13: 1405, 15: 1391
            }
        else:
            # Shorts ã®ã¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿
            shorts = self.channel_data[self.channel_data['is_short'] == True]

            # æ›œæ—¥åˆ¥å¹³å‡è¦–è´æ•°
            self.day_of_week_stats = shorts.groupby('published_day_of_week')['view_count'].mean().to_dict()

            # æ™‚é–“å¸¯åˆ¥å¹³å‡è¦–è´æ•°
            self.hour_stats = shorts.groupby('published_hour')['view_count'].mean().to_dict()

        # å…¨ä½“å¹³å‡
        all_views = list(self.day_of_week_stats.values())
        self.overall_avg = np.mean(all_views) if all_views else 2000

        # æ™‚é–“å¸¯ã®å…¨ä½“å¹³å‡
        hour_views = list(self.hour_stats.values())
        self.hour_avg = np.mean(hour_views) if hour_views else 1800

    def extract_channel_performance_features(self, datetime_obj):
        """
        ãƒãƒ£ãƒ³ãƒãƒ«å›ºæœ‰ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç‰¹å¾´é‡ã‚’æŠ½å‡º

        Args:
            datetime_obj: datetime ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ

        Returns:
            dict: ãƒãƒ£ãƒ³ãƒãƒ«å›ºæœ‰ç‰¹å¾´é‡
        """
        features = {}

        dow = datetime_obj.weekday()
        hour = datetime_obj.hour

        # æ›œæ—¥åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
        expected_views_dow = self.day_of_week_stats.get(dow, self.overall_avg)
        features['channel_day_performance'] = expected_views_dow / self.overall_avg  # æ­£è¦åŒ–

        # æ™‚é–“å¸¯åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
        expected_views_hour = self.hour_stats.get(hour, self.hour_avg)
        features['channel_hour_performance'] = expected_views_hour / self.hour_avg  # æ­£è¦åŒ–

        # è¤‡åˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚¹ã‚³ã‚¢
        features['channel_combined_score'] = (
            features['channel_day_performance'] * 0.6 +
            features['channel_hour_performance'] * 0.4
        )

        # ãƒ™ã‚¹ãƒˆã‚¿ã‚¤ãƒŸãƒ³ã‚°ãƒ•ãƒ©ã‚°
        features['is_best_day'] = 1 if dow == 3 else 0  # æœ¨æ›œæ—¥
        features['is_best_hour'] = 1 if hour == 6 else 0  # 6æ™‚å°
        features['is_second_best_hour'] = 1 if hour == 8 else 0  # 8æ™‚å°

        # æœ€é©æ™‚é–“å¸¯ï¼ˆ6-9æ™‚ï¼‰
        features['is_morning_peak'] = 1 if 6 <= hour <= 9 else 0

        # é€±æœ«åŠ¹æœ
        features['is_weekend_boost'] = 1 if dow in [5, 6] else 0

        # ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆæœ¨æ›œæœ6-9æ™‚ãŒæœ€å¼·ï¼‰
        features['is_golden_timeslot'] = 1 if (dow == 3 and 6 <= hour <= 9) else 0

        return features

    def get_optimal_posting_times(self, top_n=10):
        """
        éå»ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãæœ€é©æŠ•ç¨¿æ™‚é–“ãƒˆãƒƒãƒ—N

        Returns:
            list: [(day_of_week, hour, expected_views), ...]
        """
        recommendations = []

        for dow, dow_views in self.day_of_week_stats.items():
            for hour, hour_views in self.hour_stats.items():
                # ç°¡æ˜“æ¨å®š: æ›œæ—¥ã¨æ™‚é–“ã®å¹³å‡
                estimated_views = (dow_views + hour_views) / 2
                recommendations.append((dow, hour, estimated_views))

        # æœŸå¾…è¦–è´æ•°ã§ã‚½ãƒ¼ãƒˆ
        recommendations.sort(key=lambda x: x[2], reverse=True)

        return recommendations[:top_n]

    def print_recommendations(self):
        """æœ€é©æŠ•ç¨¿æ™‚é–“ã®æ¨å¥¨ã‚’è¡¨ç¤º"""
        print("\n" + "="*60)
        print("ğŸ“Š ãƒãƒ£ãƒ³ãƒãƒ«å›ºæœ‰ã®æœ€é©æŠ•ç¨¿æ™‚é–“åˆ†æ")
        print("="*60)

        print(f"\nã€æ›œæ—¥åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã€‘")
        day_names = ['æœˆæ›œ', 'ç«æ›œ', 'æ°´æ›œ', 'æœ¨æ›œ', 'é‡‘æ›œ', 'åœŸæ›œ', 'æ—¥æ›œ']
        sorted_days = sorted(self.day_of_week_stats.items(), key=lambda x: x[1], reverse=True)
        for i, (dow, avg_views) in enumerate(sorted_days, 1):
            boost = (avg_views / self.overall_avg - 1) * 100
            print(f"  {i}. {day_names[dow]}: {avg_views:,.0f} views ({boost:+.0f}%)")

        print(f"\nã€æ™‚é–“å¸¯åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã€‘")
        sorted_hours = sorted(self.hour_stats.items(), key=lambda x: x[1], reverse=True)
        for i, (hour, avg_views) in enumerate(sorted_hours[:5], 1):
            boost = (avg_views / self.hour_avg - 1) * 100
            print(f"  {i}. {hour:02d}æ™‚å°: {avg_views:,.0f} views ({boost:+.0f}%)")

        print(f"\nã€æ¨å¥¨æŠ•ç¨¿ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ« TOP 10ã€‘")
        optimal = self.get_optimal_posting_times(10)
        for i, (dow, hour, expected) in enumerate(optimal, 1):
            print(f"  {i}. {day_names[dow]} {hour:02d}æ™‚ - æœŸå¾…è¦–è´æ•°: {expected:,.0f} views")

        print("\n" + "="*60)


# çµ±åˆç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢
class EnhancedFeatureEngineer:
    """
    å…ƒã® FeatureEngineer + ãƒãƒ£ãƒ³ãƒãƒ«å›ºæœ‰ç‰¹å¾´é‡ã‚’çµ±åˆ
    """

    def __init__(self, channel_history_path='channel_history.csv'):
        self.channel_engineer = ChannelSpecificFeatureEngineer(channel_history_path)

    def extract_all_features(self, datetime_obj, song_data=None, taiko_data=None):
        """
        å…¨ç‰¹å¾´é‡ã‚’æŠ½å‡ºï¼ˆå…ƒã®ç‰¹å¾´é‡ + ãƒãƒ£ãƒ³ãƒãƒ«å›ºæœ‰ç‰¹å¾´é‡ï¼‰

        Args:
            datetime_obj: æŠ•ç¨¿äºˆå®šæ—¥æ™‚
            song_data: æ›²ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            taiko_data: Taikoã‚µãƒ¼ãƒãƒ¼ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

        Returns:
            dict: çµ±åˆç‰¹å¾´é‡
        """
        # ãƒãƒ£ãƒ³ãƒãƒ«å›ºæœ‰ç‰¹å¾´é‡
        features = self.channel_engineer.extract_channel_performance_features(datetime_obj)

        # åŸºæœ¬çš„ãªæ™‚é–“ç‰¹å¾´é‡ã‚‚è¿½åŠ ï¼ˆå…ƒã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¨ã®äº’æ›æ€§ï¼‰
        features['hour'] = datetime_obj.hour
        features['day_of_week'] = datetime_obj.weekday()
        features['month'] = datetime_obj.month
        features['is_weekend'] = 1 if datetime_obj.weekday() >= 5 else 0

        # å‘¨æœŸã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
        features['hour_sin'] = np.sin(2 * np.pi * datetime_obj.hour / 24)
        features['hour_cos'] = np.cos(2 * np.pi * datetime_obj.hour / 24)
        features['day_sin'] = np.sin(2 * np.pi * datetime_obj.weekday() / 7)
        features['day_cos'] = np.cos(2 * np.pi * datetime_obj.weekday() / 7)

        return features


def main():
    """ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    print("="*60)
    print("ãƒãƒ£ãƒ³ãƒãƒ«å›ºæœ‰ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ")
    print("="*60)

    engineer = ChannelSpecificFeatureEngineer()
    engineer.print_recommendations()

    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹
    print("\nã€ç‰¹å¾´é‡æŠ½å‡ºãƒ†ã‚¹ãƒˆã€‘")
    test_cases = [
        datetime(2025, 12, 18, 6, 0),   # æœ¨æ›œ 6æ™‚ (æœ€å¼·)
        datetime(2025, 12, 18, 8, 0),   # æœ¨æ›œ 8æ™‚
        datetime(2025, 12, 16, 15, 0),  # ç«æ›œ 15æ™‚
    ]

    day_names = ['æœˆæ›œ', 'ç«æ›œ', 'æ°´æ›œ', 'æœ¨æ›œ', 'é‡‘æ›œ', 'åœŸæ›œ', 'æ—¥æ›œ']

    for dt in test_cases:
        features = engineer.extract_channel_performance_features(dt)
        print(f"\n{day_names[dt.weekday()]} {dt.hour:02d}:00")
        print(f"  æ›œæ—¥ã‚¹ã‚³ã‚¢: {features['channel_day_performance']:.3f}")
        print(f"  æ™‚é–“ã‚¹ã‚³ã‚¢: {features['channel_hour_performance']:.3f}")
        print(f"  ç·åˆã‚¹ã‚³ã‚¢: {features['channel_combined_score']:.3f}")
        print(f"  ã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ã‚¿ã‚¤ãƒ : {'âœ“' if features['is_golden_timeslot'] else 'âœ—'}")


if __name__ == '__main__':
    main()
